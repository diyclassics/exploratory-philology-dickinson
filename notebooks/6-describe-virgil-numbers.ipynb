{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describe: Counting numbers in Virgil"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devise\n",
    "How numerous are numbers in Latin poetry? It is one of those questions that a reader may have a vague sense of through the act of reading, but which would be difficult to quantify through reading alone. Surely you could read a Latin poem keeping a numeric scorecard as work through the text. In fact that is what we will do, or more precisely what we will task the computer with doing, since this is the kind of the \"reading\" at which the excel. So, for this experiment, let's build a number counter that reads the works of Virgil—the *Eclogues*, the *Georgics*, the *Aeneid*—and keeps a tally of numbers that are encountered in each texts. We will then use the results to offer a provisional answer to the question—which of Virgil's works is the most \"numerical\"?\n",
    "\n",
    "Is this a good research question? It is surely not a completely uninteresting one. But what I want you to keep in mind as we develop this exercise—it is not so much that we are interested in \"numericalness\" as much as we are interested in description in general. How do we go about describing the texts we read? Sure we have some familiar ways of describing texts, e.g. genre. The *Aeneid* is an epic poem. The *Eclogues* is a collection of bucolic poetry. The *Georgics* are... well, sometimes I'm not sure I really know what the *Georgics* are, but they are certainly some sort of didactic poem. But once we are able to discern formals features of texts, identify them, collect and count them, we can describe any number of literary phenomena. I could have just as easily chosen \"animalness\" in Virgil or \"colorfulness\" in Virgil. (We will in fact look at color in later in this notebook.) Here we start with numbers and we do so for a specific reason. Numbers—for the most part, and for our purposes in this experiment, entirely so—are indeclinable. That means that we can restrict our attention, at least at first, to the wordform as it appears in the text, i.e. the token, and not to its dictionary definition, i.e. the lemma. But don't worry we will get to lemmas soon after."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan\n",
    "\n",
    "What do we need to do to determine Virgilian \"numericalness\"? Before we write out any Python code, we turn first to pseudocode, i.e. a plain language description of the steps we will take to solve our problem. As I see the problem given above, we need to do the following...\n",
    "\n",
    "**Pseudocode for counting numbers in Virgil**\n",
    "\n",
    "- Load our library of Latin texts, keeping only those by Virgil\n",
    "- Create a list of words that we will consider numbers\n",
    "- For each text by Virgil...\n",
    "    - Read the text into memory\n",
    "    - Count the words in the text that are also in the our number list\n",
    "    - Store the count of numbers in the text\n",
    "- Create a table of number counts\n",
    "\n",
    "As you will see below, we will qualify how we present this table of counts, spec. normalizing the counts by text length. But for now we our pseudocode provides an excellent starting point for proceeding with our Describe experiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary imports\n",
    "from natsort import natsorted\n",
    "from pprint import pprint\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, let's set up our corpus reader and pull out the texts we want to describe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC 1: Load our library of Latin texts, keeping only those by Virgil\n",
    "\n",
    "from cltkreaders.lat import LatinTesseraeCorpusReader\n",
    "\n",
    "T = LatinTesseraeCorpusReader()\n",
    "\n",
    "eclogues = natsorted([fileid for fileid in T.fileids() if 'eclogues' in fileid])\n",
    "georgics = natsorted([fileid for fileid in T.fileids() if 'georgics' in fileid])\n",
    "aeneid = natsorted([fileid for fileid in T.fileids() if 'aeneid' in fileid])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here how we use the `natsorted` function from the `natsort` package to sort the fileids in the order we \"naturally\" expect. Compare the difference..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vergil.aeneid.part.1.tess',\n",
      " 'vergil.aeneid.part.10.tess',\n",
      " 'vergil.aeneid.part.11.tess',\n",
      " 'vergil.aeneid.part.12.tess',\n",
      " 'vergil.aeneid.part.2.tess',\n",
      " 'vergil.aeneid.part.3.tess',\n",
      " 'vergil.aeneid.part.4.tess',\n",
      " 'vergil.aeneid.part.5.tess',\n",
      " 'vergil.aeneid.part.6.tess',\n",
      " 'vergil.aeneid.part.7.tess',\n",
      " 'vergil.aeneid.part.8.tess',\n",
      " 'vergil.aeneid.part.9.tess']\n"
     ]
    }
   ],
   "source": [
    "# What we do not want...\n",
    "aeneid = [fileid for fileid in T.fileids() if 'aeneid' in fileid]\n",
    "pprint(aeneid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how the file for Book 1 is followed by Books 10, 11, 12 before getting to Book 2. This is because the files are sorted by Python string value and not according to our philological sensibilities. So we use `natsorted` to fix this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vergil.aeneid.part.1.tess',\n",
      " 'vergil.aeneid.part.2.tess',\n",
      " 'vergil.aeneid.part.3.tess',\n",
      " 'vergil.aeneid.part.4.tess',\n",
      " 'vergil.aeneid.part.5.tess',\n",
      " 'vergil.aeneid.part.6.tess',\n",
      " 'vergil.aeneid.part.7.tess',\n",
      " 'vergil.aeneid.part.8.tess',\n",
      " 'vergil.aeneid.part.9.tess',\n",
      " 'vergil.aeneid.part.10.tess',\n",
      " 'vergil.aeneid.part.11.tess',\n",
      " 'vergil.aeneid.part.12.tess']\n"
     ]
    }
   ],
   "source": [
    "# What we want...\n",
    "aeneid = natsorted([fileid for fileid in T.fileids() if 'aeneid' in fileid])\n",
    "pprint(aeneid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find items in our texts, we will test for inclusion using the `in` operator. For example, we can check whether the number 'seven', i.e. *septem*, is in the text of the *Eclogues* by using the following code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "eclogues_words = list(T.words(eclogues))\n",
    "pprint('septem' in eclogues_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is! And since this word in both indeclinable and unambiguous with respect to lemma (i.e. there is no other Latin word that has an oblique form *septem*), we can be confident that we have found what we are looking for. Same for *octo*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print('octo' in eclogues_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word *octo* does not appear in the *Eclogues*. Again, we make this determination by checking for inclusion with the `in` operator. In order to get to where we want to go with this experiment, all we need to do is scale up our process—check more words against more texts, keeping track of what we find along the way. Let's continue with the *Eclogues* and, instead of checking individual numbers, we will loop over a list of numbers, checking each one against the text. As noted above, we will skip the \"declinable\" numbers for now and limit ourselves to the numbers four through ten, i.e. the \"indeclinables.\"\n",
    "\n",
    "First, we make a list of numbers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC 2: Create a list of words that we will consider numbers\n",
    "\n",
    "numbers = ['quattuor', 'quinque', 'sex', 'septem', 'octo', 'nouem', 'decem']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and then loop over this list. For now, we will just print `True` when the number is encountered and `False` when it is not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Checking 'quattuor' in eclogues_words...\n",
      "Found quattuor!\n",
      "--------------------\n",
      "--------------------\n",
      "Checking 'quinque' in eclogues_words...\n",
      "Not found.\n",
      "--------------------\n",
      "--------------------\n",
      "Checking 'sex' in eclogues_words...\n",
      "Not found.\n",
      "--------------------\n",
      "--------------------\n",
      "Checking 'septem' in eclogues_words...\n",
      "Found septem!\n",
      "--------------------\n",
      "--------------------\n",
      "Checking 'octo' in eclogues_words...\n",
      "Not found.\n",
      "--------------------\n",
      "--------------------\n",
      "Checking 'nouem' in eclogues_words...\n",
      "Not found.\n",
      "--------------------\n",
      "--------------------\n",
      "Checking 'decem' in eclogues_words...\n",
      "Found decem!\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for number in numbers:\n",
    "    print('--------------------')\n",
    "    print(f\"Checking '{number}' in eclogues_words...\")\n",
    "    if number in eclogues_words:\n",
    "        print(f'Found {number}!')\n",
    "    else:\n",
    "        print(f'Not found.')\n",
    "    print('--------------------')\n",
    "    sleep(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surely, though it would be better to keep track of, not only whether a word is seen or not, but also of how many times we see it. We can do this easily enough by using a data structure specifically designed for this task, namely `Counter`. `Counter` is a dictionary-like structure in which keys, i.e. here the number words, are mapped to values, i.e. the number of times the key is seen. We just need to increment the count, i.e. add one to the existing value, every time a new instance of the number word is seen. We will once again use the `in` operator to check for inclusion, but note that this time we reverse the test—instead of checking whether the number word is in the text, we check whether each word in the text is in the list of number words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'decem': 2, 'septem': 1, 'quattuor': 1})\n"
     ]
    }
   ],
   "source": [
    "# PC 3a & b: \n",
    "#    - Count the words in the text that are also in the our number list\n",
    "#    - Store the count of numbers in the text\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "C = Counter()\n",
    "\n",
    "for word in eclogues_words:\n",
    "    if word in numbers:\n",
    "        C[word] += 1\n",
    "\n",
    "print(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not a lot of number words. Again, think back to the 'Devise' section—as a reader of the *Eclogues* you may intuit that numbers just do not come up often. But could you have read the ten poems start to finish and announced that you had seen the number *septem* only once? Probably not.\n",
    "\n",
    "As we have already started to see in the previous exercises, one of the most empowering things about computational approaches to philological problems is the flexibility that comes from simple refactoring. With a change of very little, only a line or two of code, we can switch easily from the \"numericalness\" of the *Eclogues* to that of the *Georgics*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "georgics_words = list(T.words(georgics))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's just get the *Aeneid* words out of the way now too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeneid_words = list(T.words(aeneid))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Counter` works pretty fast and—in the interest of showing the many different ways to approach a philological problem—let's arrive at our number counts in a slightly different way this time. Let's build a counter for each poem with **all** of the words and then only keep the counts of interest, i.e. the number words. We do this not with a list comprehension, like e.g. we have seen when working with our file list, but rather a dictionary comprehension.\n",
    "\n",
    "It works like so... we loop over the numbers list and make each number a key in the dictionary while assigning that key the value from the complete word count. A nice trick and an efficient one—it takes no more time to count everything and select from what we have than to loop over everything and add what we want and it is likely faster. Loops have their place in coding and we will use them often. But we should recognize too that there are often more efficient ways to approach problems. We will see this over and over again in this book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quattuor': 6, 'quinque': 0, 'sex': 0, 'septem': 3, 'octo': 1, 'nouem': 0, 'decem': 1}\n"
     ]
    }
   ],
   "source": [
    "eclogues_C = Counter(eclogues_words)\n",
    "georgics_C = Counter(georgics_words)\n",
    "aeneid_C = Counter(aeneid_words)\n",
    "\n",
    "eclogues_nums_C = {k: eclogues_C[k] for k in numbers}\n",
    "georgics_nums_C = {k: georgics_C[k] for k in numbers}\n",
    "aeneid_nums_C = {k: aeneid_C[k] for k in numbers}\n",
    "\n",
    "# Print an example\n",
    "print(georgics_nums_C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know have three Counters with \"numericalness\" data from each of Virgil's works. Let's present them in a tabular format so that we can compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quattuor</th>\n",
       "      <th>quinque</th>\n",
       "      <th>sex</th>\n",
       "      <th>septem</th>\n",
       "      <th>octo</th>\n",
       "      <th>nouem</th>\n",
       "      <th>decem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eclogues</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgics</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aeneid</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          quattuor  quinque  sex  septem  octo  nouem  decem\n",
       "Eclogues         1        0    0       1     0      0      2\n",
       "Georgics         6        0    0       3     1      0      1\n",
       "Aeneid           7        1    4      12     0      0      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PC 4: Create a table of number counts\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([eclogues_nums_C, georgics_nums_C, aeneid_nums_C], index=['Eclogues', 'Georgics', 'Aeneid'])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *Aeneid* has more numbers than the other two works—at least, more of the numbers 4 through 10. But this twelve-book epic poem is also much longer than the other works. Is this a fair comparison? No, so let's take the added step of normalizing the existing counts. We do this by dividing each count by the number of words in the corresponding text. To make things more readable—these are afterall very low wordcounts—we multiply the result by 1000 and make things even more readable we can round this number to two decimal places. What we have then is a count per 1000 words which we can use as a basis for comparison. First, we need word counts. This is all straightforward enough, though making it all work compactly verges towards an advance topic. Here is how you could approach it—don't worry if all of the details are not clear yet. We will explore Pandas in greater depth as the book progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7201 words in the Eclogues.\n"
     ]
    }
   ],
   "source": [
    "eclogues_words_total = len(eclogues_words)\n",
    "georgics_words_total = len(georgics_words)\n",
    "aeneid_words_total = len(aeneid_words)\n",
    "\n",
    "# Print an example\n",
    "print(f'There are {eclogues_words_total} words in the Eclogues.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quattuor</th>\n",
       "      <th>quinque</th>\n",
       "      <th>sex</th>\n",
       "      <th>septem</th>\n",
       "      <th>octo</th>\n",
       "      <th>nouem</th>\n",
       "      <th>decem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Eclogues</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgics</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aeneid</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          quattuor  quinque   sex  septem  octo  nouem  decem\n",
       "Eclogues      0.14     0.00  0.00    0.14  0.00    0.0   0.28\n",
       "Georgics      0.36     0.00  0.00    0.18  0.06    0.0   0.06\n",
       "Aeneid        0.09     0.01  0.05    0.15  0.00    0.0   0.03"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = [eclogues_words_total, georgics_words_total, aeneid_words_total]\n",
    "\n",
    "df_norm = df.div(counts, axis='rows').mul(1000).round(2)\n",
    "df_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what we really want is a total of our words of interest over the total word count..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eclogues     4\n",
       "Georgics    11\n",
       "Aeneid      26\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nums = df.sum(axis=1)\n",
    "df_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eclogues    0.555\n",
       "Georgics    0.655\n",
       "Aeneid      0.326\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nums.div(counts, axis='rows').mul(1000).round(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm that we understand how Pandas arrives at this number for the *Eclogues*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: 4 number words / 7201 total words = 0.0005610885117127227\n",
      "Step 2: ( 4 number words / 7201 total words ) * 1000 = 0.5610885117127227\n",
      "Step 3: \"        \"        \"    rounded to the third decimal place = 0.561\n"
     ]
    }
   ],
   "source": [
    "print(f'Step 1: 4 number words / {eclogues_words_total} total words = {4/7129}')\n",
    "print(f'Step 2: ( 4 number words / {eclogues_words_total} total words ) * 1000 = {(4/7129) * 1000}')\n",
    "print(f'Step 3: \"        \"        \"    rounded to the third decimal place = {round((4/7129) * 1000, 3)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So while the *Aeneid* has more number words in absolute terms that the other two works, in relative terms it has fewer. And the *Georgics* edges out the *Eclogues*—at least as we defined the problem—i.e. as a count of the indeclinable numbers *quattuor* through *decem*. Let's see what we can do now with lemmas and not just tokens.\n",
    "\n",
    "We will use a data structure available to us in the Tesserae CorpusReader called `tokenized_sents` which generates one sentence at a time in the format of a list of length-three tuples of the form (*token*, *lemma*, *POS tag*). Here is an example from the beginning of the *Eclogues*..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Tityre', 'tityrus', 'PROPN'),\n",
      " (',', ',', 'PUNCT'),\n",
      " ('tu', 'tu', 'PRON'),\n",
      " ('patulae', 'patula', 'NOUN'),\n",
      " ('recubans', 'recubo', 'VERB')]\n"
     ]
    }
   ],
   "source": [
    "eclogues_tokenized_sents = T.tokenized_sents(eclogues)\n",
    "\n",
    "pprint(next(eclogues_tokenized_sents)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can increase our list of numbers now to include the 'declinables', i.e. the Latin words for the numbers one through three. And we can do so using lemmas, since we now have access to that information through the `tokenized_sents`. Having increased the number list, we can iterate once again over our texts to get updated counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unus': 5, 'duo': 6, 'tres': 2, 'quattuor': 1, 'quinque': 0, 'sex': 0, 'septem': 1, 'octo': 0, 'nouem': 0, 'decem': 2}\n"
     ]
    }
   ],
   "source": [
    "numbers = ['unus', 'duo', 'tres', 'quattuor', 'quinque', 'sex', 'septem', 'octo', 'nouem', 'decem']\n",
    "\n",
    "eclogues_tokenized_sents = T.tokenized_sents(eclogues)\n",
    "\n",
    "eclogues_lemmas = []\n",
    "\n",
    "for sent in eclogues_tokenized_sents:\n",
    "    for word, lemma, pos in sent:\n",
    "        eclogues_lemmas.append(lemma)\n",
    "\n",
    "eclogues_C = Counter(eclogues_lemmas)\n",
    "\n",
    "eclogues_nums_C = {k: eclogues_C[k] for k in numbers}        \n",
    "\n",
    "# Print an example\n",
    "print(eclogues_nums_C)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unus': 12, 'duo': 6, 'tres': 2, 'quattuor': 7, 'quinque': 0, 'sex': 2, 'septem': 3, 'octo': 1, 'nouem': 0, 'decem': 1}\n"
     ]
    }
   ],
   "source": [
    "georgics_tokenized_sents = T.tokenized_sents(georgics)\n",
    "\n",
    "georgics_lemmas = []\n",
    "\n",
    "for sent in georgics_tokenized_sents:\n",
    "    for word, lemma, pos in sent:\n",
    "        georgics_lemmas.append(lemma)\n",
    "\n",
    "georgics_C = Counter(georgics_lemmas)\n",
    "\n",
    "georgics_nums_C = {k: georgics_C[k] for k in numbers}\n",
    "\n",
    "# Print an example\n",
    "print(georgics_nums_C)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'unus': 113, 'duo': 22, 'tres': 12, 'quattuor': 7, 'quinque': 1, 'sex': 8, 'septem': 12, 'octo': 0, 'nouem': 4, 'decem': 2}\n"
     ]
    }
   ],
   "source": [
    "aeneid_tokenized_sents = T.tokenized_sents(aeneid)\n",
    "\n",
    "aeneid_lemmas = []\n",
    "\n",
    "for sent in aeneid_tokenized_sents:\n",
    "    for word, lemma, pos in sent:\n",
    "        aeneid_lemmas.append(lemma)\n",
    "\n",
    "aeneid_C = Counter(aeneid_lemmas)\n",
    "\n",
    "aeneid_nums_C = {k: aeneid_C[k] for k in numbers}\n",
    "\n",
    "# Print an example\n",
    "print(aeneid_nums_C)        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine these again into a dataframe of raw counts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eclogues     17\n",
       "Georgics     34\n",
       "Aeneid      181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df = pd.DataFrame([eclogues_nums_C, georgics_nums_C, aeneid_nums_C], index=['Eclogues', 'Georgics', 'Aeneid'])\n",
    "lemma_df_nums = lemma_df.sum(axis=1)\n",
    "lemma_df_nums"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and again normalize by total number of words in each text per 1000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eclogues    2.36\n",
       "Georgics    2.02\n",
       "Aeneid      2.27\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df_nums_norm = lemma_df_nums.div(counts, axis='rows').mul(1000).round(2)\n",
    "lemma_df_nums_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our increased wordlist—lemma list really—we see a shift the results. The high number of *unus* instances shifts the *Aeneid* into the lead as the most numerical of the three works with the *Georgics* slipping to third. But these are only results, not conclusions. So many questions remain: does this match our prior expectation of Virgilian \"numericalness\" from our reading experience? Is the count of *unus* correct, i.e. how accurate is our lemmatizer? (see *Error analysis* below) What about numbers higher than 10? etc. But while questions remain, it is also true that we have these questions because we were able with a reasonable amount of effort to engage in some exploratory textual data analysis with our texts. To apporach these questions with pen-and-paper would take hours; with Python, it takes minutes and this is a considerable extension of our philological toolkit."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "- ***Change author***: What if we wanted to compare the \"numericalness\" of Virgil's works to those of another author? How would we do this? What other authors might we compare to Virgil? Perhaps we could try the experiment again with Ovid? or Lucan?\n",
    "- ***Change concept***: What if, instead of \"numericalness, we want to capture a different concept? What if we wanted to compare the \"animalness\" of Virgil's works? How might we approach this problem? (Hint: we could start with a single animal word, e.g. *equus*, and then expand to an increasingly longer list of animal words.) How are animals (or other concepts) different from numbers? Or, stated differently, could you ever compose a complete list of animal words?\n",
    "- ***Compare against existing arguments***: J.C. Bramble (following André 1949) writes that Lucan's use of color volcabulary is \"less rich than that of mainstream epic\" and that it is a \"predominantly monchrome epic.\" Does this bear itself out under further scrutiny? (It may be further helpful to consult Bramble's loose statistical account of this phenomenon, e.g. does *virens* appear only once in Lucan (and specifically at 9.523? is it the only \"green\" word?) Or when we see that Bramble writes—\"From a total of 34 terms, white, grey and black are the dominant tones, accounting for in terms with 64 occurrences.\"—how can operationalize this loose definition of color terms into something that can be quantified using the methods above?\n",
    "- ***Error analysis*** Our results are only as good as our data and the tools/methods applied to our data. So, it is important that we have a sense of the accuracy of what has been output to the tables above. E.g. the [lemmatizer](https://huggingface.co/latincy/la_core_web_lg) used in the `tokenized_sents` method above has a reported accuracy of 94.6%—good, but obviously not perfect. One place where we should already have some pause—for our word counts in the Aeneid, we have *sex* at 6 instances and in our lemmas counts we have 8 instances. Something is off—as a next step, it would be a good idea to open up the Aeneid texts and search and/or read through the file to see what may be happening. It is good to do this kind of error analysis periodically so that we are aware of what is working well and what isn't in our philological explorations.\n",
    "\n",
    "### For the future\n",
    "\n",
    "- ***Model concepts*** Under *Change concept* above, I asked \"Could you ever compose a complete list of animal words?\" The answer is of course no. And even if you could there would be a question of whether iterating over a longer and longer list would be the best computational approach to our problem. What if instead we were to train a model to the recognize concept words? i.e. predict how likely any given word is a color word or an animal word etc. This brings us into the world of entity recognition (and more generally into the world of machine learning) which is beyond the scope of this workshop. But it is good to start thinking about the limits of our current approaches while we also lay the ground work for expanding our methodological range going forward. See for example [this article](https://www.turing.com/kb/a-comprehensive-guide-to-named-entity-recognition) for an overview of entity recognition."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "- Jacques André. 1949. *Étude sur les termes de couleur dans la langue latine*. Paris: Librairie C. Klincksieck.\n",
    "- Bramble, J.C. 1983. “Lucan.” In Kenney, E.J. ed. *Cambridge History Latin Literature: The Early Principate*. Cambridge: Cambridge University Press. 533–57.\n",
    "- Bradley, M. 2009. *Colour and Meaning in Ancient Rome*. Cambridge Classical Studies. Cambridge: Cambridge University Press.\n",
    "- Gries, S.T. 2016. Quantitative Corpus Linguistics with R: A Practical Introduction. 2nd ed. New York: Routledge. doi:10.4324/9781315746210. Spec. Ch. 2.2 on \"frequency lists\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('exploratory-philology')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "90f29fce041a746dff5b4e7dc43fcbd6facb181eb5d3b96918a0244a9c00c3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
